# üß™ Proyecto de Pruebas de Carga y Rendimiento con Apache JMeter

## üìã Descripci√≥n General
Este proyecto contiene una serie de pruebas de carga automatizadas utilizando **Apache JMeter**, enfocadas en evaluar el rendimiento de APIs p√∫blicas mediante escenarios reproducibles.  
El prop√≥sito es medir **tiempos de respuesta**, **tolerancia al estr√©s** y **comportamiento bajo m√∫ltiples usuarios simult√°neos**.

---

## üß± Estructura del Proyecto


## ‚öôÔ∏è Configuraci√≥n del Entorno

### 1Ô∏è‚É£ Requisitos previos
- Java JDK 8 o superior  
- Apache JMeter 5.6.x  
- Variables de entorno configuradas:
  JMETER_HOME = C:\apache-jmeter-5.6.3
  PATH += %JMETER_HOME%\bin

Para verificar:
jmeter -v

---

## üöÄ Escenarios de Prueba

### üß© 1. JSONPlaceholder ‚Äì Prueba de rendimiento
**Archivo:** JSONPlaceholderPerformanceTest.jmx  
**Objetivo:** Evaluar la respuesta de la API `/posts` con m√∫ltiples usuarios.  

**Configuraci√≥n:**
- 10 usuarios simult√°neos  
- 5 repeticiones  
- Endpoint: https://jsonplaceholder.typicode.com/posts  
- M√©todo: GET

**Ejecuci√≥n CLI:**
jmeter -n -t JSONPlaceholderPerformanceTest.jmx -l resultados.jtl -e -o reporte_html

---

### üë• 2. ReqRes API ‚Äì Prueba de carga
**Archivo:** ReqResLoadTest.jmx  
**Objetivo:** Simular 50 usuarios simult√°neos contra el endpoint `/api/users`.  

**Configuraci√≥n:**
- 50 usuarios  
- Ramp-Up: 5 segundos  
- Endpoint: https://reqres.in/api/users  
- M√©todo: GET

**Ejecuci√≥n CLI:**
jmeter -n -t ReqResLoadTest.jmx -l reqres_resultados.jtl -e -o reqres_reporte_html

‚ö†Ô∏è Si aparece el error "Results file is not empty", elimina el archivo `.jtl` anterior antes de volver a ejecutar:
del reqres_resultados.jtl

---

### üê∂ 3. Swagger Petstore ‚Äì Prueba de estr√©s
**Archivo:** SwaggerPetstoreStressTest.jmx  
**Objetivo:** Realizar un stress test a `/pet/findByStatus` con 200 requests/minuto.  

**Configuraci√≥n:**
- 100 hilos (usuarios virtuales)
- Ramp-Up: 30 segundos
- Duraci√≥n: 1 minuto
- Endpoint base: https://petstore.swagger.io/v2
- Request: GET /pet/findByStatus?status=available

**Ejecuci√≥n CLI:**
jmeter -n -t SwaggerPetstoreStressTest.jmx -l petstore_resultados.jtl -e -o petstore_reporte_html

---

## üìä Reportes y Resultados
Tras ejecutar cualquier prueba, se genera un reporte HTML en la carpeta indicada:

reporte_html/
reqres_reporte_html/
petstore_reporte_html/

Para visualizar el resultado:
- Abrir el archivo index.html en el navegador.
- Revisar m√©tricas como:
  - Throughput (solicitudes por segundo)
  - Response time (tiempo medio y m√°ximo)
  - Error rate (porcentaje de errores)
  - Latency (latencia media)

---

## üß† An√°lisis T√©cnico
Cada .jmx incluye:
- Thread Group: Configura los usuarios virtuales y ramp-up.
- HTTP Request Defaults: Define el dominio base.
- HTTP Request Sampler: Define las peticiones espec√≠ficas.
- View Results Tree / Summary Report: Para revisi√≥n manual.
- Backend Listener (opcional): Para integraci√≥n con InfluxDB + Grafana.

---

## üß© C√≥digo Base Ejemplo (XML JMX)
Ejemplo reducido de un test plan .jmx:

<jmeterTestPlan version="1.2" properties="5.0">
  <hashTree>
    <TestPlan testname="ReqRes Load Test" enabled="true">
      <hashTree>
        <ThreadGroup num_threads="50" ramp_time="5" duration="60" scheduler="true">
          <hashTree>
            <HTTPSamplerProxy testname="GET Users" enabled="true">
              <stringProp name="HTTPSampler.domain">reqres.in</stringProp>
              <stringProp name="HTTPSampler.path">/api/users</stringProp>
              <stringProp name="HTTPSampler.method">GET</stringProp>
            </HTTPSamplerProxy>
          </hashTree>
        </ThreadGroup>
      </hashTree>
    </TestPlan>
  </hashTree>
</jmeterTestPlan>

---

## üßæ Commits Recomendados

git init
git add .
git commit -m "feat: configuraci√≥n inicial de proyecto JMeter"
git commit -m "test: a√±adir prueba de rendimiento para JSONPlaceholder"
git commit -m "test: crear prueba de carga para ReqRes API con 50 usuarios"
git commit -m "test: agregar stress test para Swagger Petstore con 200 req/minuto"
git commit -m "docs: incluir documentaci√≥n t√©cnica completa en README.md"


*************************************************************************************
Estructura de la colecci√≥n JSONPlaceholder API Testing.collection

CRUD b√°sico (/posts)

GET /posts ‚Üí Lista de posts.

GET /posts/{id} ‚Üí Consulta un post por ID.

POST /posts ‚Üí Crea un nuevo post.

PUT /posts/{id} ‚Üí Actualiza un post existente.

DELETE /posts/{id} ‚Üí Elimina un post.

Relaciones

GET /posts/{id}/comments ‚Üí Comentarios de un post.

GET /users/{id}/posts ‚Üí Posts de un usuario.

Casos negativos

IDs inexistentes.

Payloads inv√°lidos.

M√©todos no permitidos (PUT /posts, PATCH /posts/1, DELETE /posts).

Performance

Validaci√≥n de tiempo de respuesta < 2 segundos.

Validaci√≥n de tama√±o de respuesta (< 1 MB).

‚úÖ Validaciones incluidas

Status codes esperados (200, 201, 204, 400, 404, 405).

Esquema JSON: validaci√≥n de campos requeridos y tipos de datos.

Casos negativos: asegurando que la API no acepte datos inv√°lidos.

Performance: tiempo de respuesta y tama√±o de respuesta.

üîß Ejecuci√≥n en Postman

Importar el archivo collection.json.

Ejecutar manualmente los requests o correr toda la colecci√≥n.

Revisar los tests en la pesta√±a Tests de cada request o en el Collection Runner.

üî® Ejecuci√≥n con Newman

Instalar Newman (si no lo tienes):

npm install -g newman


Ejecutar la colecci√≥n:

newman run collection.json


Generar reporte HTML:

newman run collection.json -r html


El reporte se genera en un archivo newman.html que muestra:

N√∫mero total de pruebas.

Resultados (pasadas/fallidas).

Tiempos de respuesta por request.

üìä Evidencias

Archivo JSON de la colecci√≥n (collection.json).

Reporte HTML de Newman (newman.html).

///////////////////////////////////////////////////


Estructura de la colecci√≥n ReqRes API Testing

Autenticaci√≥n (/api/login, /api/register)

POST /api/login ‚Üí Login exitoso con credenciales v√°lidas.
POST /api/login ‚Üí Login fallido con credenciales inv√°lidas o incompletas.
POST /api/register ‚Üí Registro exitoso de nuevo usuario.
POST /api/register ‚Üí Registro fallido (falta de par√°metros).

Gesti√≥n de usuarios (CRUD en /api/users)

GET /api/users ‚Üí Lista de usuarios.
GET /api/users/{id} ‚Üí Consulta un usuario por ID.
POST /api/users ‚Üí Crea un nuevo usuario.
PUT /api/users/{id} ‚Üí Actualiza un usuario existente.
DELETE /api/users/{id} ‚Üí Elimina un usuario.

Paginaci√≥n (/api/users?page=2)

GET /api/users?page=2 ‚Üí Valida respuestas paginadas (n√∫mero de p√°gina, cantidad de registros, total de p√°ginas, etc.).

Rate Limiting (Simulaci√≥n)

GET /api/users?page=1 ‚Üí Detecci√≥n de l√≠mites de requests (429 Too Many Requests).
Validaci√≥n de encabezados:
- X-RateLimit-Limit
- X-RateLimit-Remaining

Casos negativos

- IDs inexistentes en /api/users/{id}
- Campos faltantes o payloads inv√°lidos en /api/login y /api/register
- M√©todos no permitidos (PUT /api/users, PATCH /api/users/1, DELETE /api/users)
- Validaci√≥n de respuesta vac√≠a o error 404 cuando el recurso no existe

Performance

- Validaci√≥n de tiempo de respuesta < 2 segundos
- Validaci√≥n de tama√±o de respuesta < 1 MB

Validaciones incluidas

- Status codes esperados: 200, 201, 204, 400, 404, 429
- Esquema JSON: validaci√≥n de campos requeridos y tipos de datos
- Casos negativos: asegura que la API no acepte datos inv√°lidos
- Performance: tiempos de respuesta y tama√±o de payload
- Rate Limiting: manejo de error 429 Too Many Requests

Ejecuci√≥n en Postman

1. Importar el archivo ReqRes_API_Collection.json.
2. Configurar el entorno si es necesario (variables base URL).
3. Ejecutar manualmente los requests o correr toda la colecci√≥n desde el Collection Runner.
4. Verificar los resultados en la pesta√±a Tests o en el resumen de ejecuci√≥n.

Ejecuci√≥n con Newman

Instalar Newman (si no lo tienes):
npm install -g newman

Ejecutar la colecci√≥n:
newman run ReqRes_API_Collection.json

Generar reporte HTML:
newman run ReqRes_API_Collection.json -r html

El reporte newman.html incluye:
- N√∫mero total de pruebas ejecutadas
- Resultados (pasadas/fallidas)
- C√≥digos de estado devueltos
- Tiempos de respuesta por request

Evidencias

- Archivo JSON de la colecci√≥n: ReqRes_API_Collection.json
- Reporte HTML de Newman: newman.html
- README.md: Documentaci√≥n t√©cnica y de ejecuci√≥n

*************************************************

üßæ README ‚Äî Proyecto de Automatizaci√≥n con Selenium (Java)

üìå Descripci√≥n General
Este proyecto contiene una serie de pruebas automatizadas E2E (end-to-end) realizadas con Selenium WebDriver, TestNG y Java, enfocadas en validar funcionalidades del sitio de pr√°ctica The Internet (https://the-internet.herokuapp.com/).

El objetivo principal es demostrar habilidades en automatizaci√≥n de pruebas funcionales, manejo de elementos din√°micos, autenticaci√≥n, formularios complejos y validaci√≥n de carga/descarga de archivos.

‚öôÔ∏è Tecnolog√≠as Utilizadas
- Lenguaje: Java
- Framework de pruebas: TestNG
- Automatizaci√≥n Web: Selenium WebDriver
- IDE recomendado: IntelliJ IDEA
- JDK recomendado: JDK 17
- Gesti√≥n de dependencias: Maven
- Navegador: Google Chrome (v140 o superior)
- Driver: ChromeDriver compatible con la versi√≥n del navegador


üöÄ Casos Automatizados

1Ô∏è‚É£ Formularios Complejos (/checkboxes, /dropdown, /dynamic_controls)
- Selecci√≥n y deselecci√≥n de checkboxes.
- Validaci√≥n de selecci√≥n en dropdowns.
- Habilitar/deshabilitar campos din√°micos.
- Verificaci√≥n de mensajes de √©xito tras cada acci√≥n.

2Ô∏è‚É£ Autenticaci√≥n (/login)
Credenciales v√°lidas:
Usuario: tomsmith
Contrase√±a: SuperSecretPassword!
- Login exitoso y fallido.
- Validaci√≥n de mensajes de alerta.
- Prevenci√≥n de alerta de guardado de contrase√±a en Chrome.

3Ô∏è‚É£ Elementos Din√°micos (/dynamic_loading/1 y /dynamic_loading/2)
- Detecci√≥n y espera de elementos cargados din√°micamente.

4Ô∏è‚É£ Carga y Descarga de Archivos (/upload y /download)
- Subida de archivos desde el sistema local.
- Validaci√≥n del nombre del archivo subido.
- Descarga y verificaci√≥n del archivo descargado.

üí¨ Ejecuci√≥n de las Pruebas
1. Clonar el repositorio
   git clone https://github.com/bralquibar-arch/selenium-automation.git
   cd selenium-automation

2. Instalar dependencias
   mvn clean install

3. Ejecutar todas las pruebas
   mvn test

4. O ejecutar una clase espec√≠fica
   mvn -Dtest=AuthenticationLogin test

üß† Buenas Pr√°cticas Implementadas
- Uso de Page Object Model (POM).
- Esperas expl√≠citas (WebDriverWait).
- Configuraci√≥n avanzada de Chrome.
- Asserts claros y mensajes personalizados.
- Commits descriptivos.

üßæ Ejemplo de Commits Descriptivos
git commit -m "Implementaci√≥n de pruebas E2E para login exitoso y fallido"
git commit -m "Automatizaci√≥n de formularios complejos con checkboxes y dropdowns"
git commit -m "Agregadas pruebas para elementos din√°micos (dynamic_loading)"
git commit -m "Automatizadas pruebas de carga y descarga de archivos"
git commit -m "Optimizaci√≥n de tiempos de espera y manejo de popups en Chrome"


